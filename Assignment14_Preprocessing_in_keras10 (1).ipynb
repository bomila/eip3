{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Assignment14_Preprocessing in keras10.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfqPC9Kcgczg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "import os, os.path\n",
        "import pandas as pd\n",
        "import math\n",
        "np.random.seed(2019)\n",
        "import time\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "import keras.callbacks as callbacks\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import plot_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "#import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7P6XFyS63QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.models\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout,Conv2D\n",
        "from keras.layers.normalization import BatchNormalization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE2TWooZhCcZ",
        "colab_type": "text"
      },
      "source": [
        "## **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4wbAb9PhGjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a09c4d9f-8a0c-4b18-8f0f-4ac5192dc439"
      },
      "source": [
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "num_classes = len(np.unique(trainY))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXQEhjgt0zlq",
        "colab_type": "text"
      },
      "source": [
        "### used for slicing the image(tensorflow function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEyRT1gJ0yVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((testX, testY))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igbdhFT621PT",
        "colab_type": "text"
      },
      "source": [
        "**Get shape of training and test images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsDghtKBhSvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dbd888b-b489-4739-ffc3-7c9fb82563f4"
      },
      "source": [
        "len_train, len_test = len(trainX), len(testX)\n",
        "print(trainX.shape, trainY.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK0wn96pnap1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale the test and train data\n",
        "\n",
        "trainX = trainX.astype('float32')/255\n",
        "testX = testX.astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAmKxcyRhfkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "nb_epoch = 50\n",
        "img_rows, img_cols = 32, 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzZoAn99xVWI",
        "colab_type": "text"
      },
      "source": [
        "**standard scaling: subtract by mean, and divide by standard deviation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUAnJkJKnPjM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6e495df-2cc8-4ed3-83a2-12373a477fa6"
      },
      "source": [
        "# mean value \n",
        "train_mean=np.array([0.4914, 0.4822, 0.4465])\n",
        "train_mean"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz4pD6X0nvda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "314106a4-d36b-4ea6-ff6a-cc7be08a58cd"
      },
      "source": [
        "# std value \n",
        "train_std=np.array([0.2023, 0.1994, 0.2010])\n",
        "train_std"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2023, 0.1994, 0.201 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wnjRtC7n94K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to normalize train and test image\n",
        "trainX = (trainX - train_mean) / train_std\n",
        "testX = (testX - train_mean) / train_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvqSd5RTol2d",
        "colab_type": "text"
      },
      "source": [
        "**In DavidNet**\n",
        "\n",
        "\n",
        "training images go through the standard Cifar10 transformations, that is: \n",
        "\n",
        "* pad 4 pixels to 40×40, crop back to 32×32.\n",
        "\n",
        "* apply random crop to the image\n",
        "\n",
        "* randomly flip left and right. \n",
        "\n",
        "* In addition, it apply the popular Cutout augmentation as a regularization measure, which alleviates overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hkAOu4Po_8F",
        "colab_type": "text"
      },
      "source": [
        "### function to pad training image by 4 pixel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga54TJgOo61G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad4(x):\n",
        "    return np.pad(x, ((0,0), (4, 4), (4, 4),(0,0)), mode='reflect')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsYrHU7ypNmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = pad4(trainX)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oBqDhvgpYOg",
        "colab_type": "text"
      },
      "source": [
        "###Function to randomly crop the training image and random flips of the image(tensorflow function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMmkYx-72IQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to randomly crop the training image and random horizontal flips of the image\n",
        "#data_aug = lambda x, y: (tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3])), y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXBT7JBv2ITY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## map function to apply the augmentation to each element\n",
        "#trainset = train_dataset.map(data_aug).shuffle(len_train).batch(batch_size).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea9KzBMd3WPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl6BCz_j3Q6x",
        "colab_type": "text"
      },
      "source": [
        "### **keras random crop function **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIazQmfe3Vg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_crop(x, random_crop_size = (32,32), sync_seed=None):\n",
        "    np.random.seed(sync_seed)\n",
        "    w, h = x.shape[1], x.shape[2]\n",
        "    rangew = (w - random_crop_size[0]) // 2\n",
        "    rangeh = (h - random_crop_size[1]) // 2\n",
        "    offsetw = 0 if rangew == 0 else np.random.randint(rangew)\n",
        "    offseth = 0 if rangeh == 0 else np.random.randint(rangeh)\n",
        "    return x[:, offsetw:offsetw+random_crop_size[0], offseth:offseth+random_crop_size[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9xMkyXM3dR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X=random_crop(trainX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A436MQ_3wRO",
        "colab_type": "text"
      },
      "source": [
        "### convert class labels to binary class labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggLZPKM73vGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = np_utils.to_categorical(trainY, num_classes)\n",
        "testY = np_utils.to_categorical(testY, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO3Gr8A66url",
        "colab_type": "text"
      },
      "source": [
        "### Build Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRqBYuBc6eqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "def model1():\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), border_mode='same',kernel_regularizer=regularizers.l2(0.0001),name='conv2D_1', input_shape=(32, 32, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3),kernel_regularizer=regularizers.l2(0.0001),name='conv2D_2',border_mode='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv2D(32, (1, 1),name='conv2D_3'))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3),kernel_regularizer=regularizers.l2(0.0001),name='conv2D_4',border_mode='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3),kernel_regularizer=regularizers.l2(0.0001),name='conv2D_5',border_mode='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(32, (1, 1),name='conv2D_6'))\n",
        "  \n",
        "  model.add(Conv2D(128, (3, 3),kernel_regularizer=regularizers.l2(0.0001),name='conv2D_7', border_mode=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3),kernel_regularizer=regularizers.l2(0.0001),name='conv2D_8', border_mode=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(10, (1, 1),name='conv2D_9'))\n",
        "\n",
        "  model.add(AveragePooling2D(pool_size = (4,4)))\n",
        "  model.add(Flatten())\n",
        "\n",
        "\n",
        "  model.add(Activation('softmax'))\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l8uVhIy6leS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "d8849622-a493-4032-e094-7db110ed6e7a"
      },
      "source": [
        "model = model1()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0810 14:25:39.009887 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_1\", input_shape=(32, 32, 3..., padding=\"same\")`\n",
            "  after removing the cwd from sys.path.\n",
            "W0810 14:25:39.016397 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0810 14:25:39.019019 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0810 14:25:39.084425 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0810 14:25:39.085701 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0810 14:25:41.878724 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_2\", padding=\"same\")`\n",
            "  \n",
            "W0810 14:25:42.065200 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0810 14:25:42.074858 140378280564608 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_4\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_5\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_7\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_8\", padding=\"same\")`\n",
            "W0810 14:25:42.617054 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp94FURr6vwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9efe260c-cae2-430b-fb48-944fd6d7d9f5"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0810 14:26:39.019538 140378280564608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR85d5t97JdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "38efdb68-be7d-4e4c-ae77-5010b9773bbe"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n",
        "model = model1()\n",
        "\n",
        "filepath='saved_model1'\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=filepath, monitor='val_acc', mode='auto', verbose = 1, save_best_only=True)\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_acc',factor=0.8, cooldown=0, patience=5, min_lr=0.5e-9,verbose = 1)\n",
        "\n",
        "# Compile the model\n",
        "sgd = optimizers.SGD(lr=0.01, decay=0, momentum=0.9, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=sgd)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_1\", input_shape=(32, 32, 3..., padding=\"same\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_2\", padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_4\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_5\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_7\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), kernel_regularizer=<keras.reg..., name=\"conv2D_8\", padding=\"same\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEJJFT3q7X04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aeaf6278-dc38-4a61-a048-7152ce0d07c7"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "                             \n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_X, trainY, batch_size = 128),\n",
        "                                 samples_per_epoch = trainX.shape[0], nb_epoch = 100, \n",
        "                                 validation_data = (testX, testY),callbacks=[checkpointer,lr_reducer], verbose=1)\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(X_test, Y_test, model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., verbose=1, steps_per_epoch=390, epochs=100)`\n",
            "  if sys.path[0] == '':\n",
            "W0810 14:29:48.360789 140378280564608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 32s 83ms/step - loss: 1.5337 - acc: 0.4634 - val_loss: 1.3650 - val_acc: 0.5235\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.52350, saving model to saved_model1\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.1304 - acc: 0.6111 - val_loss: 1.1095 - val_acc: 0.6183\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.52350 to 0.61830, saving model to saved_model1\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.9827 - acc: 0.6683 - val_loss: 0.9979 - val_acc: 0.6630\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.61830 to 0.66300, saving model to saved_model1\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.8745 - acc: 0.7066 - val_loss: 0.9144 - val_acc: 0.7012\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66300 to 0.70120, saving model to saved_model1\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.7862 - acc: 0.7382 - val_loss: 0.9250 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.70120\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.7280 - acc: 0.7606 - val_loss: 0.8688 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.70120 to 0.71430, saving model to saved_model1\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6827 - acc: 0.7782 - val_loss: 0.7943 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.71430 to 0.74000, saving model to saved_model1\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6423 - acc: 0.7918 - val_loss: 0.7701 - val_acc: 0.7465\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.74000 to 0.74650, saving model to saved_model1\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6005 - acc: 0.8080 - val_loss: 0.7582 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.74650 to 0.75450, saving model to saved_model1\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5764 - acc: 0.8163 - val_loss: 0.8570 - val_acc: 0.7402\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.75450\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.5440 - acc: 0.8272 - val_loss: 0.6784 - val_acc: 0.7813\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.75450 to 0.78130, saving model to saved_model1\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5227 - acc: 0.8357 - val_loss: 0.7580 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.78130\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5004 - acc: 0.8443 - val_loss: 0.6758 - val_acc: 0.7963\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.78130 to 0.79630, saving model to saved_model1\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4734 - acc: 0.8518 - val_loss: 0.6968 - val_acc: 0.7905\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.79630\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4619 - acc: 0.8595 - val_loss: 0.6496 - val_acc: 0.7985\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.79630 to 0.79850, saving model to saved_model1\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4442 - acc: 0.8629 - val_loss: 0.6521 - val_acc: 0.8017\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.79850 to 0.80170, saving model to saved_model1\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4266 - acc: 0.8698 - val_loss: 0.6792 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80170\n",
            "Epoch 18/100\n",
            "305/390 [======================>.......] - ETA: 5s - loss: 0.4145 - acc: 0.8733"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzLTC_nM7saK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8S6GMNr9xVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}