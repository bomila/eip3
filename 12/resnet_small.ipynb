{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_small.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLtvvrhaT8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def block(n_output, upscale=False):\n",
        "    # n_output: number of feature maps in the block\n",
        "    # upscale: should we use the 1x1 conv2d mapping for shortcut or not\n",
        "    \n",
        "    # keras functional api: return the function of type\n",
        "    # Tensor -> Tensor\n",
        "    def f(x):\n",
        "               \n",
        "        # first pre-activation\n",
        "        h = BatchNormalization()(x)\n",
        "        h = Activation(relu)(h)\n",
        "        # first convolution\n",
        "        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n",
        "        \n",
        "        # second pre-activation\n",
        "        h = BatchNormalization()(x)\n",
        "        h = Activation(relu)(h)\n",
        "        # second convolution\n",
        "        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n",
        "               \n",
        "        if upscale:\n",
        "            # 1x1 conv2d\n",
        "            f = Conv2D(kernel_size=1, filters=n_output, strides=1, padding='same')(x)\n",
        "        else:\n",
        "            # identity\n",
        "            f = x\n",
        "               \n",
        "        return add([f, h])\n",
        "    \n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUfSR7fRaVSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_tensor = Input((32,32, 3))\n",
        "\n",
        "# first conv2d with post-activation to transform the input data to some reasonable form\n",
        "x = Conv2D(kernel_size=3, filters=16, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(input_tensor)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(relu)(x)\n",
        "\n",
        "# F_1\n",
        "x = block(16)(x)\n",
        "# F_2\n",
        "x = block(16)(x)\n",
        "\n",
        "# F_3\n",
        "x = block(32, upscale=True)(x)       \n",
        "# F_4\n",
        "x = block(32)(x)                    \n",
        "# F_5\n",
        "x = block(32)(x)                   \n",
        "# F_6\n",
        "x = block(48, upscale=True)(x)      \n",
        "# F_7\n",
        "x = block(48)(x)                     \n",
        "\n",
        "# last activation of the entire network's output\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(relu)(x)\n",
        "\n",
        "# average pooling across the channels\n",
        "# 28x28x48 -> 1x48\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# dropout for more robust learning\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last softmax layer\n",
        "x = Dense(units=10, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "x = Activation(softmax)(x)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}